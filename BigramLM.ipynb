{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BigramLM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ramaseshanr/anlp/blob/master/BigramLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "qObtsZDj1yXr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#This code may have snippets taken from the Internet\n",
        "import nltk\n",
        "from nltk import bigrams\n",
        "\n",
        "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
        "import numpy as np\n",
        "\n",
        "import collections\n",
        "from collections import Counter\n",
        "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
        "\n",
        "corpusdir = '/your/Corpus/'  # point to the Directory of corpus.\n",
        "kinematics_corpus = PlaintextCorpusReader(corpusdir, '.*')\n",
        "\n",
        "#compute the bigram model\n",
        "def build_bigram_model():\n",
        "    bigram_model = collections.defaultdict(lambda: collections.defaultdict(lambda: 0))\n",
        "    for sentence in kinematics_corpus.sents():\n",
        "        sentence = [word.lower() for word in sentence if word.isalpha()]  # get alpha only\n",
        "        #Collect all bigrams counts for (w1,w2)\n",
        "        for w1, w2 in bigrams(sentence):\n",
        "            bigram_model[w1][w2] += 1\n",
        "        #compute the probability for the bigram starting with w1\n",
        "        for w1 in bigram_model:\n",
        "            #total count of bigrams starting with w1\n",
        "            total_count = float(sum(bigram_model[w1].values()))\n",
        "            #distribute the probability mass for all bigrams starting with w1\n",
        "            for w2 in bigram_model[w1]:\n",
        "                bigram_model[w1][w2] /= total_count\n",
        "    return bigram_model\n",
        "\n",
        "\n",
        "def predict_next_word(first_word):\n",
        "    #buikd the model\n",
        "    model = build_bigram_model()\n",
        "    #get the next for the bigram starting with 'word'\n",
        "    second_word = model[first_word]\n",
        "    #get the top 10 words whose first word is 'first_word'\n",
        "    top10words = Counter(second_word).most_common(10)\n",
        "\n",
        "\n",
        "    predicted_words = list(zip(*top10words))[0]\n",
        "    probability_score = list(zip(*top10words))[1]\n",
        "    x_pos = np.arange(len(predicted_words))\n",
        "\n",
        "    # calculate slope and intercept for the linear trend line\n",
        "    slope, intercept = np.polyfit(x_pos, probability_score, 1)\n",
        "\n",
        "    plt.bar(x_pos, probability_score,align='center')\n",
        "    plt.xticks(x_pos, predicted_words)\n",
        "    plt.ylabel('Probability Score')\n",
        "    plt.xlabel('Predicted Words')\n",
        "    plt.title('Predicted words for ' + first_word)\n",
        "    plt.show()\n",
        "\n",
        "predict_next_word('how')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}