{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TopicModeling_LSI.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ramaseshanr/anlp/blob/master/TopicModeling_LSI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQPKu_7IyqAo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "outputId": "4461d314-0fe0-4e99-c57e-e43a18cd733c"
      },
      "source": [
        "import os\n",
        "import gensim\n",
        "from gensim.models import LsiModel\n",
        "from gensim import models\n",
        "from gensim import corpora\n",
        "from gensim.utils import lemmatize\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.parsing.preprocessing import remove_stopwords, stem_text\n",
        "from gensim.parsing.preprocessing import strip_numeric, strip_short,strip_multiple_whitespaces,strip_non_alphanum,strip_punctuation,strip_tags,preprocess_string\n",
        "import pandas as pd\n",
        "from gensim import similarities\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "import matplotlib.pyplot as plt\n",
        "from pprint import pprint\n",
        "\n",
        "\n",
        "\n",
        "#read the data\n",
        "corpus_dir = 'https://raw.githubusercontent.com/Ramaseshanr/anlp/master/corpus/bbc-text.csv'\n",
        "df_corpus = pd.read_csv(corpus_dir,names=['category', 'text'])\n",
        "corpus = df_corpus['text'].values.tolist()\n",
        "corpus = corpus[1:]\n",
        "my_filter = [\n",
        "    lambda x: x.lower(), strip_tags, strip_punctuation,\n",
        "    strip_multiple_whitespaces, strip_numeric,\n",
        "    remove_stopwords, strip_short, stem_text\n",
        "]\n",
        "\n",
        "\n",
        "def preprocessing(corpus):\n",
        "\n",
        "    for document in corpus:\n",
        "        doc = strip_numeric(document)\n",
        "        doc = remove_stopwords(doc)\n",
        "        doc = strip_short(doc,3)\n",
        "        doc = stem_text(doc)\n",
        "        doc = strip_punctuation(doc)\n",
        "        strip_tags(doc)\n",
        "        yield gensim.utils.tokenize(doc, lower=True)\n",
        "\n",
        "\n",
        "texts = preprocessing(corpus)\n",
        "dictionary = corpora.Dictionary(texts)\n",
        "dictionary.filter_extremes(no_below=1, keep_n=700)\n",
        "\n",
        "doc_term_matrix = [dictionary.doc2bow(tokens) for tokens in preprocessing(corpus)]\n",
        "tfidf = models.TfidfModel(doc_term_matrix)\n",
        "corpus_tfidf = tfidf[doc_term_matrix]\n",
        "\n",
        "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=10)  # initialize an LSI transformation\n",
        "pprint(lsi.print_topics(num_topics=10, num_words=10))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0,\n",
            "  '0.135*\"game\" + 0.128*\"film\" + 0.094*\"bn\" + 0.093*\"peopl\" + 0.091*\"plai\" + '\n",
            "  '0.086*\"music\" + 0.084*\"compani\" + 0.083*\"best\" + 0.082*\"govern\" + '\n",
            "  '0.082*\"firm\"'),\n",
            " (1,\n",
            "  '0.293*\"film\" + 0.206*\"game\" + 0.188*\"award\" + -0.175*\"labour\" + '\n",
            "  '0.174*\"best\" + 0.154*\"plai\" + -0.149*\"bn\" + -0.144*\"elect\" + -0.141*\"tax\" + '\n",
            "  '0.138*\"win\"'),\n",
            " (2,\n",
            "  '0.243*\"labour\" + -0.222*\"film\" + 0.215*\"blair\" + 0.188*\"elect\" + '\n",
            "  '0.181*\"parti\" + 0.165*\"tori\" + 0.147*\"brown\" + -0.135*\"mobil\" + -0.132*\"bn\" '\n",
            "  '+ -0.128*\"firm\"'),\n",
            " (3,\n",
            "  '0.531*\"film\" + 0.267*\"award\" + -0.197*\"game\" + 0.179*\"best\" + 0.170*\"actor\" '\n",
            "  '+ 0.169*\"star\" + 0.160*\"labour\" + 0.136*\"blair\" + -0.127*\"england\" + '\n",
            "  '0.123*\"elect\"'),\n",
            " (4,\n",
            "  '-0.291*\"mobil\" + -0.254*\"phone\" + 0.214*\"bn\" + -0.180*\"technolog\" + '\n",
            "  '-0.169*\"user\" + -0.164*\"music\" + 0.154*\"bank\" + -0.147*\"peopl\" + '\n",
            "  '-0.138*\"digit\" + 0.132*\"m\"'),\n",
            " (5,\n",
            "  '-0.239*\"mobil\" + -0.193*\"economi\" + -0.189*\"growth\" + -0.180*\"rate\" + '\n",
            "  '0.173*\"law\" + 0.172*\"court\" + -0.160*\"phone\" + -0.155*\"game\" + '\n",
            "  '-0.146*\"brown\" + -0.131*\"econom\"'),\n",
            " (6,\n",
            "  '-0.472*\"music\" + 0.418*\"film\" + -0.201*\"song\" + -0.178*\"best\" + '\n",
            "  '-0.178*\"award\" + 0.171*\"england\" + -0.137*\"singl\" + -0.136*\"record\" + '\n",
            "  '-0.117*\"sale\" + 0.116*\"wale\"'),\n",
            " (7,\n",
            "  '0.363*\"game\" + 0.213*\"m\" + 0.204*\"film\" + 0.171*\"club\" + -0.170*\"award\" + '\n",
            "  '-0.159*\"rate\" + 0.148*\"bn\" + -0.147*\"best\" + -0.147*\"economi\" + '\n",
            "  '0.136*\"mobil\"'),\n",
            " (8,\n",
            "  '-0.518*\"mobil\" + -0.453*\"phone\" + 0.342*\"game\" + 0.171*\"music\" + '\n",
            "  '0.131*\"sale\" + 0.117*\"releas\" + 0.112*\"site\" + -0.111*\"award\" + '\n",
            "  '-0.110*\"champion\" + -0.107*\"best\"'),\n",
            " (9,\n",
            "  '-0.257*\"lord\" + -0.213*\"england\" + -0.212*\"music\" + 0.198*\"mail\" + '\n",
            "  '0.174*\"user\" + 0.171*\"site\" + 0.169*\"net\" + -0.159*\"wale\" + -0.147*\"mobil\" '\n",
            "  '+ 0.146*\"champion\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}