{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Ramaseshanr/ANLP/blob/master/TF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "f7MSm5-wY_P9",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ezs0QnTNDI3B",
    "colab_type": "code",
    "outputId": "7c8e350d-e1e8-4842-f31a-b593f544a919",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 660.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     /home/ramaseshan/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package gutenberg to\n[nltk_data]     /home/ramaseshan/nltk_data...\n[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Word  Frequency\n0  little        597\n1    said        453\n2    came        191\n3     one        183\n4   could        158\n5    king        141\n6    went        122\n7   would        112\n8   great        110\n9     day        107\n\n      Word  Weighted Frequency\n0   little            0.161876\n1     said            0.122831\n2     came            0.051790\n3      one            0.049620\n4    could            0.042842\n5     king            0.038232\n6     went            0.033080\n7    would            0.030369\n8    great            0.029826\n9      day            0.029013\n10     man            0.029013\n11     old            0.028200\n12    time            0.026302\n13     see            0.026302\n14    like            0.024946\n15     saw            0.024946\n16    away            0.024675\n17  mother            0.024403\n18    made            0.024132\n19    good            0.022777\n"
     ]
    }
   ],
   "source": [
    "#  MIT License\n",
    "#  Copyright (c) 2019.\n",
    "#  Project Name: ANLP\n",
    "#  File name: code.py\n",
    "#  Last modification date: 2/28/19 2:32 PM\n",
    "#  Author: ramaseshan\n",
    "#  Email:ramaseshanr@yahoo.com\n",
    "#  /TF.py\n",
    "# \n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('gutenberg')\n",
    "from nltk.probability import  FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "#read the corpus\n",
    "words = nltk.Text(nltk.corpus.gutenberg.words('bryant-stories.txt'))\n",
    "#convert to small letters\n",
    "words=[word.lower() for word in words if word.isalpha() ]\n",
    "words=[word.lower() for word in words if word not in stop_words ]\n",
    "\n",
    "fDist = FreqDist(words)\n",
    "\n",
    "#print(len(words)) #21718\n",
    "#print(len(set(words))) #3688 - unique words\n",
    "heading = ['Word','Frequency']\n",
    "tf_list = []\n",
    "for x,v in fDist.most_common(10):\n",
    "    tf_list.append((x,v))\n",
    "print(pd.DataFrame(tf_list,columns=heading))\n",
    "\n",
    "heading = ['Word','Weighted Frequency']\n",
    "tf_list = []\n",
    "\n",
    "print()\n",
    "for x,v in fDist.most_common(20):\n",
    "    tf_list.append((x,v/len(fDist)))\n",
    "print(pd.DataFrame(tf_list,columns=heading))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "TF.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
