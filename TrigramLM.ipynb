{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrigramLM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ramaseshanr/anlp/blob/master/TrigramLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpDoa8xnsPvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk import trigrams\n",
        "\n",
        "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import collections\n",
        "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
        "\n",
        "corpusdir = '/your/2019/Corpus/'  # Directory of corpus.\n",
        "your_corpus = PlaintextCorpusReader(corpusdir, '.*')\n",
        "\n",
        "def build_trigram_model():\n",
        "    trigram_model = collections.defaultdict(lambda: collections.defaultdict(lambda: 0))\n",
        "    #for sentence in gutenberg.sents(\"austen-emma.txt\"):\n",
        "\n",
        "    for sentence in your_corpus.sents():\n",
        "        sentence = [word.lower() for word in sentence if word.isalpha()]  # get alpha only\n",
        "\n",
        "        for w1, w2, w3 in trigrams(sentence, pad_right=True, pad_left=True):\n",
        "            trigram_model[(w1, w2)][w3] += 1\n",
        "\n",
        "        for w1_w2 in trigram_model:\n",
        "            trigram_count_4_w1w2 = float(sum(model[w1_w2].values()))\n",
        "            for w3 in model[w1_w2]:\n",
        "                trigram_model[w1_w2][w3] /= trigram_count_4_w1w2\n",
        "\n",
        "    return trigram_model\n",
        "\n",
        "\n",
        "def predict_next_word(w1,w2):\n",
        "    model = trigram_model()\n",
        "    next_word = model[(w1,w2)]\n",
        "    predicted_words = Counter(next_word).most_common(10)\n",
        "\n",
        "\n",
        "    top10Predicted_words = list(zip(*predicted_words))[0]\n",
        "    probability_score = list(zip(*predicted_words))[1]\n",
        "    x_pos = np.arange(len(top10Predicted_words))\n",
        "\n",
        "    # calculate slope and intercept for the linear trend line\n",
        "    slope, intercept = np.polyfit(x_pos, probability_score, 1)\n",
        "\n",
        "    plt.bar(x_pos, probability_score,align='center')\n",
        "    plt.xticks(x_pos, top10Predicted_words)\n",
        "    plt.title('Predicted words for  '+ w1 + ' ' + w2)\n",
        "    plt.ylabel('Probability Score')\n",
        "    plt.xlabel('Predicted Words')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "predict_next_word('how', 'far')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}